{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJptKBxALl-u",
        "outputId": "d95fb62e-9fdd-4c23-8416-1b974b211a2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.10/dist-packages (1.5.1)\n"
          ]
        }
      ],
      "source": [
        "# Calls all the heavenly GODS\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "!pip install torchsummary\n",
        "from torchsummary import summary"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Checks if CUDA is available and sets it as device. If unavailable, CPU is used.\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00Owi1LBNY8L",
        "outputId": "c21ce457-c04a-4e82-a08a-871a1dec496a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pipeline which reads MNIST data from torch hosted datasets, applies transformations to standardize the images.\n",
        "# The output of this pipeline is then sent to the model for training\n",
        "\n",
        "batch_size = 128 # defines the smallest grouped unit of images\n",
        "\n",
        "# Data is divided into 2 sections -\n",
        "# 1) train dataset - this is used in training the model\n",
        "# 2) test dataset - this is used in testing the model\n",
        "\n",
        "# creates a data pre-processing pipeline for train dataset\n",
        "train_loader = torch.utils.data.DataLoader(                          # reads data from torch hosted api\n",
        "    datasets.MNIST('../data', train=True, download=True,             # download=True creates local copy of data, destination location for downloading images is given as input along with train=True which reads training data\n",
        "                    transform=transforms.Compose([                   # creates a pipeline to apply transformations\n",
        "                        transforms.ToTensor(),                       # function to convert to tensor data type\n",
        "                        transforms.Normalize((0.1307,), (0.3081,))   # function to normalize images based on mean and std dev\n",
        "                    ])),\n",
        "    batch_size=batch_size, shuffle=True)                             # the smallest group that is read at a time and then its shuffled before transforming\n",
        "\n",
        "# creates a data pre-processing pipeline for test dataset\n",
        "test_loader = torch.utils.data.DataLoader(                                      # reads data from torch hosted api\n",
        "    datasets.MNIST('../data', train=False, transform=transforms.Compose([       # reads test data and creates a pipeline to apply transformations\n",
        "                        transforms.ToTensor(),                                  # function to convert to tensor data type\n",
        "                        transforms.Normalize((0.1307,), (0.3081,))              # function to normalize images based on mean and std dev\n",
        "                    ])),\n",
        "    batch_size=batch_size, shuffle=True)                                        # the smallest group that is read at a time and then its shuffled before transforming"
      ],
      "metadata": {
        "id": "EQZaZRGcNLtr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Some Notes on our naive model\n",
        "\n",
        "We are going to write a network based on what we have learnt so far.\n",
        "\n",
        "The size of the input image is 28x28x1. We are going to add as many layers as required to reach RF = 32 \"atleast\"."
      ],
      "metadata": {
        "id": "r3gEjf-xMb-N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model structure\n",
        "\n",
        "class FirstDNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(FirstDNN, self).__init__()\n",
        "    # r_in:1, n_in:28, j_in:1, s:1, r_out:3, n_out:28, j_out:1\n",
        "    self.conv1 = nn.Conv2d(1, 32, 3, padding=1)\n",
        "    # r_in:3 , n_in:28 , j_in:1 , s:1 , r_out:5 , n_out:28 , j_out:1\n",
        "    self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "    # r_in:5 , n_in:28 , j_in:1 , s:2 , r_out:6 , n_out:14 , j_out:2\n",
        "    self.pool1 = nn.MaxPool2d(2, 2)\n",
        "    # r_in:6 , n_in:14 , j_in:2 , s:1 , r_out:10 , n_out:14 , j_out:2\n",
        "    self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
        "    # r_in:10 , n_in:14 , j_in:2 , s:1 , r_out:14 , n_out:14 , j_out:2\n",
        "    self.conv4 = nn.Conv2d(128, 256, 3, padding = 1)\n",
        "    # r_in:14 , n_in:14 , j_in:2 , s:2 , r_out:16 , n_out:7 , j_out:4\n",
        "    self.pool2 = nn.MaxPool2d(2, 2)\n",
        "    # r_in:16 , n_in:7 , j_in:4 , s:1 , r_out:24 , n_out:7 , j_out:4\n",
        "    self.conv5 = nn.Conv2d(256, 512, 3)\n",
        "    # r_in:24 , n_in:7 , j_in:4 , s:1 , r_out:32 , n_out:7 , j_out:4\n",
        "    self.conv6 = nn.Conv2d(512, 1024, 3)\n",
        "    # r_in:32 , n_in:7 , j_in:4 , s:1 , r_out:40 , n_out:7 , j_out:4\n",
        "    self.conv7 = nn.Conv2d(1024, 10, 3)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.pool1(F.relu(self.conv2(F.relu(self.conv1(x)))))\n",
        "    x = self.pool2(F.relu(self.conv4(F.relu(self.conv3(x)))))\n",
        "    x = F.relu(self.conv6(F.relu(self.conv5(x))))\n",
        "    x = F.relu(self.conv7(x))\n",
        "    x = x.view(-1, 10)\n",
        "    return F.log_softmax(x)\n"
      ],
      "metadata": {
        "id": "Sir2LmSVLr_4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create model and move it to the device\n",
        "model = FirstDNN().to(device)"
      ],
      "metadata": {
        "id": "sxICO4TTNt2H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# view summary of the model - the different layers, shape of their output and number of parameters\n",
        "\n",
        "summary(model, input_size=(1, 28, 28))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M__MtFIYNwXa",
        "outputId": "97ef5ffa-2b5c-4d43-f5f1-fce05d1cbce4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 28, 28]             320\n",
            "            Conv2d-2           [-1, 64, 28, 28]          18,496\n",
            "         MaxPool2d-3           [-1, 64, 14, 14]               0\n",
            "            Conv2d-4          [-1, 128, 14, 14]          73,856\n",
            "            Conv2d-5          [-1, 256, 14, 14]         295,168\n",
            "         MaxPool2d-6            [-1, 256, 7, 7]               0\n",
            "            Conv2d-7            [-1, 512, 5, 5]       1,180,160\n",
            "            Conv2d-8           [-1, 1024, 3, 3]       4,719,616\n",
            "            Conv2d-9             [-1, 10, 1, 1]          92,170\n",
            "================================================================\n",
            "Total params: 6,379,786\n",
            "Trainable params: 6,379,786\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 1.51\n",
            "Params size (MB): 24.34\n",
            "Estimated Total Size (MB): 25.85\n",
            "----------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-4356035888bc>:29: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.log_softmax(x)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "# trains the model\n",
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "    model.train() # Ensures gradient tracking is on\n",
        "    pbar = tqdm(train_loader)\n",
        "\n",
        "    # Here, we use enumerate instead of iter so that we can track the batch index and do some intra-epoch reporting\n",
        "    for batch_idx, (data, target) in enumerate(pbar):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad() # Zero gradients for every batch!\n",
        "        output = model(data)  # Make predictions for this batch\n",
        "        loss = F.nll_loss(output, target) # Compute the loss\n",
        "        loss.backward() # Compute the gradients\n",
        "        optimizer.step() # Adjust learning weights\n",
        "        pbar.set_description(desc= f'loss={loss.item()} batch_id={batch_idx}') # for reporting\n",
        "\n",
        "# performs validation/test on the model using validation/test data\n",
        "def test(model, device, test_loader):\n",
        "    model.eval() # Sets the model to evaluation mode, disables dropout and uses population statistics for batch normalization.\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():  # Disables gradient computation and reduces memory consumption.\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data) # predict output\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    # calculate average loss over the validation/test set\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    # report average loss over the validation/test set\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))"
      ],
      "metadata": {
        "id": "g_vlC-bdNzo1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Optimizers specified in the torch.optim package. Learning rate determines the size of the steps the optimizer takes.\n",
        "# Momentum nudges the optimizer in the direction of strongest gradient over multiple steps.\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "# train and test the model through several epochs. 1 epoch = 1 run through the entire dataset.\n",
        "for epoch in range(1, 2):\n",
        "    train(model, device, train_loader, optimizer, epoch)\n",
        "    test(model, device, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0FYVWkGOFBS",
        "outputId": "557788d0-9fc0-41c8-976f-629e52868090"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/469 [00:00<?, ?it/s]<ipython-input-4-4356035888bc>:29: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.log_softmax(x)\n",
            "loss=1.445028305053711 batch_id=468: 100%|██████████| 469/469 [00:33<00:00, 13.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.5995, Accuracy: 4114/10000 (41%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "reIBU667OG_c"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}